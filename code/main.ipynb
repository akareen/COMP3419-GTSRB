{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "# Part 1\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class SEDenseNet(nn.Module):\n",
    "    def __init__(self, num_classes=43):\n",
    "        super(SEDenseNet, self).__init__()\n",
    "        self.features = models.densenet121(pretrained=True).features\n",
    "        self.se_block = SEBlock(1024)\n",
    "        self.classifier = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.se_block(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import kornia as K\n",
    "\n",
    "base_transforms = transforms.Compose([\n",
    "    transforms.Resize([112, 112]),\n",
    "    transforms.ToTensor(),      \n",
    "    transforms.Lambda(lambda img: K.color.rgb_to_luv(img)) \n",
    "])\n",
    "\n",
    "\n",
    "augment_transforms = transforms.Compose([\n",
    "    transforms.Resize([112, 112]),\n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda img: K.color.rgb_to_luv(img))  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3\n",
    "\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "train_data_path = \"./data/TRAIN/\"\n",
    "\n",
    "train_data_base = datasets.ImageFolder(root=train_data_path, transform=base_transforms)\n",
    "train_data_augmented = datasets.ImageFolder(root=train_data_path, transform=augment_transforms)\n",
    "\n",
    "train_data_combined = data.ConcatDataset([train_data_base, train_data_augmented])\n",
    "\n",
    "train_size = int(0.8 * len(train_data_combined))\n",
    "val_size = len(train_data_combined) - train_size\n",
    "train_dataset, val_dataset = data.random_split(train_data_combined, [train_size, val_size])\n",
    "\n",
    "BATCH_SIZE = 256 \n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def aggregate_class_labels(data_path):\n",
    "    class_labels = []\n",
    "\n",
    "    for folder_name in os.listdir(data_path):\n",
    "        folder_path = os.path.join(data_path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            csv_file = os.path.join(folder_path, f'GT-{folder_name}.csv')\n",
    "            if os.path.isfile(csv_file):\n",
    "                df = pd.read_csv(csv_file, sep=';', usecols=['ClassId'])\n",
    "                class_labels.extend(df['ClassId'].tolist())\n",
    "\n",
    "    return np.array(class_labels)\n",
    "\n",
    "train_data_path = \"./data/TRAIN/\"\n",
    "\n",
    "classes_training = aggregate_class_labels(train_data_path)\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(classes_training), y=classes_training)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).cuda()\n",
    "\n",
    "\n",
    "model = SEDenseNet(num_classes=43).cuda()\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5\n",
    "\n",
    "import time\n",
    "\n",
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (images, labels) in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(images)\n",
    "        loss = criterion(predictions, labels)\n",
    "        acc = calculate_accuracy(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(images)\n",
    "            loss = criterion(predictions, labels)\n",
    "            acc = calculate_accuracy(predictions, labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)\n",
    "\n",
    "EPOCHS = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {val_loss:.3f}, Val. Acc: {val_acc*100:.2f}%, Time: {end_time - start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 6\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "model_save_path = './models/SEDenseNet_model.pth'\n",
    "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f'Model saved to {model_save_path}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
